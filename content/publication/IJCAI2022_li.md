+++
abstract = "Facial micro-expressions (MEs) are involuntary facial motions revealing peopleâ€™s real feelings and play an important role in the early intervention of mental illness, the national security, and many human-computer interaction systems. However, existing micro-expression datasets are limited and usually pose some challenges for training good classifiers. To model the subtle facial muscle motions, we propose a robust micro-expression recognition (MER) framework, namely muscle motion-guided network (MMNet). Specifically,  a continuous attention (CA) block is introduced to focus on modeling local subtle muscle motion patterns with little identity information, which is different from most previous methods that directly extract features from complete video frames with much identity information. Besides, we design a position calibration (PC) module based on the vision transformer. By adding the position embeddings of the face generated by the PC module at the end of the two branches, the PC module can help to add position information to facial muscle motion-pattern features for the MER. Extensive experiments on three public micro-expression datasets demonstrate that our approach outperforms state-of-the-art methods by a large margin. Code is available at https://github.com/muse1998/MMNet}{https://github.com/muse1998/MMNet."
date = "2022-04-22"
image = ""
image_preview = ""
math = false
publication = "IJCAI 2022"
publication_short = ""
selected = false
title = "MMNet: Muscle Motion-guided Network for Micro-expression Recognition"
url_code = "https://github.com/muse1998/MMNet"
url_dataset = ""
url_pdf = "https://arxiv.org/pdf/2201.05297.pdf"
url_project = "/project/deeplearning"
url_slides = ""
url_video = ""

[[authors]]
    name = "Hanting Li"
    is_member = true
[[authors]]
    name = "Mingzhe Sui"
    is_member = true
[[authors]]
    name = "Zhaoqing Zhu"
    is_member = true
[[authors]]
    name = "Feng Zhao"
    is_member = true
+++


You can add information in $\LaTeX$ and *Markdown* here.
